{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53293fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import math\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e125001",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_data_path = f\"bigresponse.json\"\n",
    "ranked_data_file = open(ranked_data_path,encoding=\"utf-8\")\n",
    "ranked_data = json.load(ranked_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d496ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = ranked_data[\"players\"]\n",
    "maps = ranked_data[\"maps\"]\n",
    "scores = ranked_data[\"scores\"]\n",
    "filtered_scores = [score for score in scores if score[\"modifiers\"] == \"\" and score[\"accuracy\"] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b8009f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_by_id = {player[\"id\"] : player for player in players}\n",
    "maps_by_id = {bmap[\"id\"] : bmap for bmap in maps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c304d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_by_player_id = {}\n",
    "scores_by_map_id = {}\n",
    "\n",
    "def add_score(score):\n",
    "    player_id = score[\"playerId\"]\n",
    "    map_id = score[\"leaderboardId\"]\n",
    "    \n",
    "    player_map = scores_by_player_id.get(player_id,{})\n",
    "    player_map[map_id] = score\n",
    "    \n",
    "    scores_by_player_id[player_id] = player_map\n",
    "    \n",
    "    map_map = scores_by_map_id.get(map_id,{})\n",
    "    map_map[player_id] = score\n",
    "    \n",
    "    scores_by_map_id[map_id] = map_map\n",
    "    \n",
    "#for score in scores:\n",
    "for score in filtered_scores:\n",
    "    add_score(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "843cdef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(v,vmin=0,vmax=500):\n",
    "    return min(max(v,vmin),vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf72db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b3fc957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a mapping on the probability space rather than the population space.\n",
    "That is, from (0,1) to (0,1). A probability distribution on the (0,1) interval.\n",
    "We can do this with the Beta distribution, though other distributions might work.\n",
    "\n",
    "I approximate a value for alpha and beta using this: https://homepage.divms.uiowa.edu/~mbognar/applets/beta.html\n",
    "Trying to get the median around 0.9 and the probability close to 0 for 0.5, but a little bit higher for 0.65ish.\n",
    "Beat Saber scores are typically at least 65%, on median probably around 0.9. They also must go down as the value\n",
    "approaches 1, so beta must be greater than 1.\n",
    "\n",
    "alpha = 10 and beta = 1.25 seemed to work quite well.\n",
    "\"\"\"\n",
    "beta_alpha = 10\n",
    "beta_beta = 1.25\n",
    "\n",
    "def beta_value(perc_value, beta_alpha=beta_alpha, beta_beta=beta_beta):\n",
    "    return scipy.stats.beta.cdf(perc_value, beta_alpha, beta_beta)\n",
    "\n",
    "def perc_beta_value(beta_value,beta_alpha=beta_alpha, beta_beta=beta_beta):\n",
    "    return scipy.stats.beta.ppf(beta_value, beta_alpha, beta_beta)\n",
    "\n",
    "\"\"\"\n",
    "After renormalizing with the beta distribution, we apply the probit value, which assumes it's centred around 0.5.\n",
    "\n",
    "We renormalize this to a value that is more typical of what we usually understand in Beat Saber.\n",
    "For example, similar to star values. This is not really meant to be accurate, though.\n",
    "\"\"\"\n",
    "\n",
    "probit_mean = 7\n",
    "probit_sd = 3\n",
    "\n",
    "def probit_value(perc_value, probit_mean=probit_mean, probit_sd = probit_sd):\n",
    "    return scipy.stats.norm.ppf(beta_value(perc_value),loc=probit_mean,scale=probit_sd)\n",
    "\n",
    "def perc_probit_value(probit_value, probit_mean=probit_mean, probit_sd = probit_sd):\n",
    "    return perc_beta_value(scipy.stats.norm.cdf(probit_value,loc=probit_mean,scale=probit_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81d98c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We take the beta renormalization of probabilities above, and instead of using a probit function,\n",
    "we map it to (0,inf) using a lognorm distribution.\n",
    "\n",
    "There isn't a strong justification for this (other than the support), but there are some arguments.\n",
    "What we want is to transform the probabilities into positive values that we can then multiply and divide in a way\n",
    "that behaves well. Multiplying two values in the lognorm support produces a new lognorm value that is\n",
    "the result of combining the other two in an independent way.\n",
    "The shape of the lognorm also matches the way that we expect these values to look.\n",
    "\"\"\"\n",
    "\n",
    "# This parameterization is NOT a mistake. Read up on lognorm parameters and try to figure out why I did this.\n",
    "# It isn't something terribly meaningful.\n",
    "lognorm_mean = 7\n",
    "lognorm_sd = 7\n",
    "log_lognorm_sd = math.log(math.log(lognorm_sd))\n",
    "\n",
    "def lognorm_value(perc_value, lognorm_mean=lognorm_mean, lognorm_sd=lognorm_sd, log_lognorm_sd=log_lognorm_sd):\n",
    "    return scipy.stats.lognorm.ppf(beta_value(perc_value),s=log_lognorm_sd,loc=0,scale=lognorm_mean)\n",
    "\n",
    "def perc_lognorm_value(lognorm_value, lognorm_mean=lognorm_mean, lognorm_sd=lognorm_sd, log_lognorm_sd=log_lognorm_sd):\n",
    "    return perc_beta_value(scipy.stats.lognorm.cdf(lognorm_value,s=log_lognorm_sd,loc=0,scale=lognorm_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357c7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Very similar idea to the above, but with a maximum value.\n",
    "\n",
    "There are some issues with this, like that a 100% score could lower a player's skill level\n",
    "if it is on a very easy map. But this is very unlikely with the numbers, and 100% scores\n",
    "are exceedingly rare anyway. There are also ways to deal with that later after estimating\n",
    "difficulties.\n",
    "\"\"\"\n",
    "\n",
    "truncexp_max = 25\n",
    "truncexp_base_mean = 7\n",
    "\n",
    "def truncexp_value(perc_value,base_mean=truncexp_base_mean):\n",
    "    return scipy.stats.truncexpon.ppf(beta_value(perc_value),b=truncexp_max,scale=base_mean)\n",
    "\n",
    "def perc_truncexp_value(truncexp_value,base_mean=truncexp_base_mean):\n",
    "    return perc_beta_value(scipy.stats.truncexpon.cdf(truncexp_value,b=truncexp_max,scale=base_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "960238b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From here onwards we assume score is linearized by using linear_score above.\n",
    "\n",
    "We normalize around a value of 7.\n",
    "This means that a X star player on a 7 accability map achieves an X star score\n",
    "and a 7 star player on an X accability map achieves an X star score.\n",
    "\"\"\"\n",
    "\n",
    "linear_mean = 7\n",
    "min_value = 0.00001\n",
    "\n",
    "def score_linear(skill,accability,linear_mean = linear_mean):\n",
    "    return skill * accability / linear_mean\n",
    "\n",
    "def accability_linear(skill,score,linear_mean = linear_mean):\n",
    "    if (skill < min_value):\n",
    "        vskill = min_value\n",
    "    else:\n",
    "        vskill = skill\n",
    "    return score / vskill * linear_mean\n",
    "\n",
    "def skill_linear(accability,score,linear_mean = linear_mean):\n",
    "    if (accability < min_value):\n",
    "        vaccability = min_value\n",
    "    else:\n",
    "        vaccability = accability\n",
    "    return score / vaccability * linear_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f132242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main idea here is that the score of a player with skill level x on a map with accability x will be x.\n",
    "In other words, the skill and accability are on the same scale as the score.\n",
    "A player with skill level x will obtain score x on a map of their corresponding accability. Etc.\n",
    "\"\"\"\n",
    "def score_equalized(skill,accability):\n",
    "    return math.sqrt(skill * accability)\n",
    "\n",
    "def accability_equalized(skill,score):\n",
    "    return score*score / skill\n",
    "\n",
    "def skill_linear(accability,score):\n",
    "    return score*score / accability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1730f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The idea above is not completely broken. The main issue lies in the relationship with the score\n",
    "being direct, which means that if one of skill / accability is larger than the other,\n",
    "the resulting score expected is closer to the lower one. That is, this \"mean\" is lower\n",
    "than the arithmetic mean, whereas in practice it should be the other way around (I think?).\n",
    "If we have values between 0 and 1, we can fix this by subtracting 1 from them.\n",
    "\n",
    "On top of that, this works best for values between 0 and 1, which are not linear when combining multiple scores.\n",
    "So what we do here is put them in probability space before combining them, then combine them\n",
    "there by subtracting them from 1.\n",
    "\"\"\"\n",
    "def score_probspace(skill, accability, value_func, perc_func):\n",
    "    return value_func(1 - math.sqrt((1 - perc_func(skill))*(1 - perc_func(accability))))\n",
    "\n",
    "def accability_probspace(skill, score, value_func, perc_func):\n",
    "    perc_score = perc_func(score)\n",
    "    inv_perc_score = 1 - perc_score\n",
    "    \n",
    "    return value_func(1 - (inv_perc_score*inv_perc_score)/(1 - perc_func(skill)))\n",
    "\n",
    "def skill_probspace(accability, score, value_func, perc_func):\n",
    "    perc_score = perc_func(score)\n",
    "    inv_perc_score = 1 - perc_score\n",
    "    \n",
    "    return value_func(1 - (inv_perc_score*inv_perc_score)/(1 - perc_func(accability)))\n",
    "\n",
    "def score_probspace_truncexp(skill, accability):\n",
    "    return score_probspace(skill, accability, truncexp_value, perc_truncexp_value)\n",
    "\n",
    "def accability_probspace_truncexp(skill, score):\n",
    "    return accability_probspace(skill, score, truncexp_value, perc_truncexp_value)\n",
    "\n",
    "def skill_probspace_truncexp(accability, score):\n",
    "    return skill_probspace(accability, score, truncexp_value, perc_truncexp_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7509b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_prop_error(value,evalue):        \n",
    "    if (value == 0):\n",
    "        vvalue = 0.0001\n",
    "    else:\n",
    "        vvalue = value\n",
    "    return abs((vvalue-evalue)/vvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "903f8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiPartiteStabilizer:\n",
    "    \"\"\"No description yet\"\"\"\n",
    "    \n",
    "    def __init__(self,anodes_ratings,bnodes_ratings,wdata,afun,bfun,wfun,default_rating=1,max_iter=50,error_fun=abs_prop_error):\n",
    "        \"\"\"\n",
    "        anodes_ratings and bnodes_ratings must be dictionaries with the node identifiers as keys\n",
    "        and initial ratings as values.\n",
    "        \n",
    "        wdata must be a doubly indexed dictionary with anode identifiers and bnode identifiers as respective indexes,\n",
    "        respectively, and weights as values.\n",
    "        \n",
    "        afun and bfun must be functions taking a value of the other node type as first argument\n",
    "        and a weight as the second argument, that returns the corresponding value for the node.\n",
    "        \n",
    "        Similarly, wfun must be a function that takes the value of an anode and bnode and returns the\n",
    "        correct weight.\n",
    "        \n",
    "        These functions must be such that:\n",
    "        - wfun(afun(b,w),b) = w\n",
    "        - wfun(a,bfun(a,w)) = w\n",
    "        - afun(bfun(a,w),w) = a\n",
    "        - afun(b,wfun(a,b)) = a\n",
    "        - bfun(afun(b,w),w) = b\n",
    "        - bfun(a,wfun(a,b)) = b\n",
    "        \n",
    "        error_fun must take two parameters (actual value, expected value) and return a number indicating the error for that\n",
    "        particular edge\n",
    "        \"\"\"\n",
    "        self.anodes_ratings = anodes_ratings\n",
    "        self.bnodes_ratings = bnodes_ratings\n",
    "        \n",
    "        self.adata = wdata\n",
    "        self.bdata = self.process_bdata(wdata)\n",
    "        \n",
    "        self.afun = afun\n",
    "        self.bfun = bfun\n",
    "        self.wfun = wfun\n",
    "        \n",
    "        self.error_fun = error_fun\n",
    "        \n",
    "        self.default_rating = default_rating\n",
    "        \n",
    "        self.average_error = math.inf\n",
    "        \n",
    "        self.iter = 0\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def process_bdata(self, wdata):\n",
    "        bdata = {}\n",
    "        \n",
    "        for anode_id, anode_data in wdata.items():\n",
    "            for bnode_id, w in anode_data.items():\n",
    "                bnode_data = bdata.get(bnode_id,{})\n",
    "                bnode_data[anode_id] = w\n",
    "                bdata[bnode_id] = bnode_data\n",
    "        \n",
    "        return bdata       \n",
    "        \n",
    "    def acycle(self):\n",
    "        aerror = 0\n",
    "        n = len(self.anodes_ratings)\n",
    "        for anode_id in self.anodes_ratings:\n",
    "            aerror += self.anode_process(anode_id)\n",
    "            \n",
    "        if (n > 0):\n",
    "            self.average_error = clamp(aerror/n)\n",
    "        else:\n",
    "            self.average_error = 0\n",
    "    \n",
    "    def anode_process(self,anode_id):\n",
    "        anode_data = self.adata[anode_id]\n",
    "        \n",
    "        asum = 0\n",
    "        n = len(anode_data)\n",
    "        for bnode_id, w in anode_data.items():\n",
    "            bnode_value = self.bnodes_ratings.get(bnode_id,self.default_rating)\n",
    "            asum += clamp(self.afun(bnode_value,w))\n",
    "        \n",
    "        if (n > 0):\n",
    "            avg = asum/n\n",
    "        else:\n",
    "            avg = 0\n",
    "        \n",
    "        self.anodes_ratings[anode_id] = clamp(avg)\n",
    "                                              \n",
    "        return self.anode_error(anode_id)\n",
    "        \n",
    "    def anode_error(self,anode_id):\n",
    "        anode_data = self.adata[anode_id]\n",
    "        anode_value = self.anodes_ratings.get(anode_id,self.default_rating)\n",
    "        \n",
    "        aerror = 0\n",
    "        n = len(anode_data)\n",
    "        for bnode_id, w in anode_data.items():\n",
    "            bnode_value = self.bnodes_ratings.get(bnode_id,self.default_rating)\n",
    "            calculated_w = clamp(self.wfun(anode_value,bnode_value))\n",
    "            error = clamp(self.error_fun(calculated_w,w))\n",
    "            aerror += error\n",
    "            \n",
    "        if (n > 0):\n",
    "            return clamp(aerror/n)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def bcycle(self):\n",
    "        for bnode_id in self.bnodes_ratings:\n",
    "            self.bnode_process(bnode_id)\n",
    "    \n",
    "    def bnode_process(self,bnode_id):\n",
    "        bnode_data = self.bdata[bnode_id]\n",
    "        \n",
    "        bsum = 0\n",
    "        n = len(bnode_data)\n",
    "        for anode_id, w in bnode_data.items():\n",
    "            anode_value = self.anodes_ratings.get(anode_id,self.default_rating)\n",
    "            bsum += clamp(self.bfun(anode_value,w))\n",
    "        \n",
    "        if (n > 0):\n",
    "            avg = bsum/n\n",
    "        else:\n",
    "            avg = 0\n",
    "        \n",
    "        self.bnodes_ratings[bnode_id] = clamp(avg)\n",
    "    \n",
    "    def iterate(self):\n",
    "        self.bcycle()\n",
    "        self.acycle()\n",
    "        \n",
    "        self.iter += 1\n",
    "        \n",
    "        print(f\"Iteration {self.iter}, Average error: {self.average_error}\")\n",
    "        \n",
    "    def run(self):\n",
    "        while (self.iter <= self.max_iter):\n",
    "            self.iterate()\n",
    "        \n",
    "        return (self.anodes_ratings,self.bnodes_ratings)\n",
    "    \n",
    "    def test(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ff8f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores_doubly_indexed = {map_id : {player_id : clamp(lognorm_value(scores_by_map_id[map_id][player_id][\"accuracy\"])) for player_id in scores_by_map_id[map_id]} for map_id in scores_by_map_id}\n",
    "scores_doubly_indexed = {map_id : {player_id : truncexp_value(scores_by_map_id[map_id][player_id][\"accuracy\"]) for player_id in scores_by_map_id[map_id]} for map_id in scores_by_map_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfed193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79980006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Average error: 0.8327359680483292\n",
      "Iteration 2, Average error: 0.9774494680197023\n",
      "Iteration 3, Average error: 1.0866453888182588\n",
      "Iteration 4, Average error: 1.1637818208373554\n",
      "Iteration 5, Average error: 1.2417819821088403\n",
      "Iteration 6, Average error: 1.3333611247847872\n",
      "Iteration 7, Average error: 1.4258855466793152\n",
      "Iteration 8, Average error: 1.5030894919325006\n"
     ]
    }
   ],
   "source": [
    "default_rating = 7\n",
    "\n",
    "map_ratings = {map_id : default_rating for map_id in scores_by_map_id}\n",
    "player_ratings = {player_id: default_rating for player_id in scores_by_player_id}\n",
    "\n",
    "bps = BiPartiteStabilizer(map_ratings,player_ratings,scores_doubly_indexed,accability_linear,skill_linear,score_linear,max_iter=7)\n",
    "#bps = BiPartiteStabilizer(map_ratings,player_ratings,scores_doubly_indexed,accability_probspace_truncexp,skill_probspace_truncexp,score_probspace_truncexp,max_iter=7)\n",
    "\n",
    "#bps.iterate()\n",
    "#(maps_1,players_1) = (copy.deepcopy(bps.anodes_ratings), copy.deepcopy(bps.bnodes_ratings))\n",
    "#bps.iterate()\n",
    "#(maps_2,players_2) = (copy.deepcopy(bps.anodes_ratings), copy.deepcopy(bps.bnodes_ratings))\n",
    "(map_ratings,player_ratings) = bps.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_outliers = {map_id : rating for (map_id,rating) in map_ratings.items() if rating > 20}\n",
    "player_outliers = {player_id : rating for (player_id,rating) in player_ratings.items() if rating > 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cec50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(map_outliers)\n",
    "print(player_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15290bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_maps = {map_id : rating for (map_id,rating) in map_ratings.items() if rating < 6}\n",
    "print(hard_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8d98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_maps = {map_id : rating for (map_id,rating) in map_ratings.items() if rating > 28}\n",
    "print(easy_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc03718",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_players = {player_id : rating for (player_id,rating) in player_ratings.items() if rating > 20}\n",
    "print(good_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f975fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(scores_doubly_indexed[\"7e8f11\"])\n",
    "#print(maps_by_id[\"387a0xxxx91\"])\n",
    "print(players_by_id[\"76561198167588802\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa814de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(map_ratings[\"3aa79xxxxxxxxx91\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c686a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_map_ratings = {map_id : rating for (map_id,rating) in map_ratings.items() if rating < 3.69 and rating > 3.68}\n",
    "print(filtered_map_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9807b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scores))\n",
    "print(len(filtered_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9685243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_by_player_id[\"76561198167588802\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66781999",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(truncexp_value(0.94))\n",
    "print(perc_truncexp_value(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(skill_probspace_truncexp(0,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e405df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_probspace_truncexp(68,68))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30dc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(skill_linear(1,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6f1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
